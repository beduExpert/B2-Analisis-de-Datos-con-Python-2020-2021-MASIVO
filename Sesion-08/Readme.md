
# Sesi칩n 08: Introducci칩n a Machine Learning: Clasificaci칩n No Supervisada y Supervisada

## :dart: Objetivos

- Conocer la definici칩n de Machine Learning, qu칠 es y c칩mo se utiliza
- Aplicar un algoritmo de K-Medias
- Interpretar los resultados de K-Medias
- Aplicar un algoritmo de Regresi칩n Log칤stica
- Evaluar un modelo de Regresi칩n Log칤stica utilizando matriz de confusi칩n y curva ROC / AUC

## 游늭 Contenido

---

<ins>쯈u칠 es Machine Learning?</ins>

Machine Learning es el estudio de algoritmos por computadora que mejoran autom치ticamente a trav칠s del entrenamiento y la experiencia. Se llama Machine **Learning** justamente por que este proceso de mejora y actualizaci칩n a trav칠s de la experiencia es lo que hacemos nosotros los humanos cuando aprendemos. Los algoritmos de Machine Learning construyen modelos matem치ticos a partir de conjuntos de datos con los que se entrenan, para poder realizar predicciones o decisiones bas치ndose en los patrones que hayan encontrado. Un humano no programa expl칤citamente el comportamiento de un algoritmo de Machine Learning, s칩lo decide sus par치metros de entrenamiento y elige el conjunto de datos con el que se le va a entrenar.

Algunas de las cosas que podemos hacer con Machine Learning son:

1. Predicci칩n: predecir qu칠 va a suceder en el futuro o predecir c칩mo se va a comportar una variable si modificamos otras variables.
2. Clasificaci칩n: clasificar una muestra univariada o multivariable dependiendo de sus caracter칤sticas.
3. Generaci칩n: aprender patrones de nuestros datos para poder generar nuevos datos que sean similares a los originales.
4. Aprendizaje no Supervisado: aprender a realizar acciones o tomar decisiones a partir de la vivencia de una situaci칩n espec칤fica.

Vamos a comentar las siguientes preguntas:

1. 쯈u칠 ejemplos conocen de cada una de estas categor칤as?
2. 쮼n qu칠 cosas de las que usamos d칤a con d칤a encontramos modelos de Machine Learning?
3. 쯉abes cu치l es la diferencia entre Machine Learning e Inteligencia Artificial?
4. 쯉abes cu치l es la diferencia entre Machine Learning y Deep Learning (Aprendizaje Profundo)?
5. 쮺칩mo crees que el uso de Machine Learning pueda cambiar el mundo en el que vivimos?
6. 쮺rees que el cambio sea para bien o para mal?

> 

---

<ins>Agrupamiento por K-Medias (Clasificaci칩n No Supervisada)</ins>

El agrupamiento por K-Medias pertenece a la categor칤a de algoritmos de clasificaci칩n no supervisada. Resulta muy 칰til cuando tenemos un dataset que queremos dividir por grupos pero no sabemos exactamente qu칠 grupos queremos y cu치les son sus caracter칤sticas. Lo 칰nico que tenemos que decidir de antemano es *cu치ntos* grupos queremos, y el algoritmo intentar치 agrupar nuestros datos en esa cantidad de grupos.

Clasificaci칩n No Supervisada quiere decir que no tenemos un conjunto de datos etiquetado de antemano. Por lo tanto, a menos que estemos dispuestos a revisar nuestro conjunto dato por dato y etiquetarlo de acuerdo a nuestros propios par치metros, la 칰nica forma de clasificar nuestros datos es utilizando un algoritmo de clasificaci칩n no supervisada.

> 

[**`Ejemplo 1`**](Ejemplo-01/k_medias.ipynb)
[**`Reto 1`**](Reto-01/k_medias.ipynb)

---

<ins>Regresi칩n Log칤stica (Clasificaci칩n Supervisada)</ins>

La regresi칩n log칤stica nos sirve para resolver problemas de clasificaci칩n binaria supervisada.

- *Binaria* significa que los datos pueden ser clasificados solamente en dos categor칤as: positivo y negativo (s칤 y no; 0 y 1).
- *Supervisada* significa que sabemos exactamente cu치les son las dos categor칤as en las que queremos agrupar a nuestros datos, y que adem치s tenemos un conjunto de datos de entrenamiento que ha sido clasificado de antemano.

쯇or qu칠 se llama Regresi칩n al igual que la Regresi칩n Lineal? La Regresi칩n Log칤stica tambi칠n busca la ecuaci칩n de una l칤nea, pero luego pasa el resultado por otro tipo de funci칩n que nos da un resultado probabil칤stico. Las probabilidades se encuentran en un intervalo entre 0 y 1. Para decidir cu치l de las dos clasificaciones regresar como resultado, definimos un *umbral* entre 0 y 1. Por ejemplo, podemos definir un umbral de 0.4. Entonces, cada vez que obtenemos una probabilidad menor a 0.4, regresamos la clasificaci칩n negativa (no; 0); de igual manera, cada vez que obtenemos un valor mayor a 0.4, regresamos una clasificaci칩n positiva (s칤; 1).

> 

[**`Ejemplo 2`**](Ejemplo-02/regresion_logistica.ipynb)
[**`Reto 2`**](Reto-02/regresion_logistica.ipynb)

---

<ins>Matriz de confusi칩n</ins>

Para evaluar un modelo de clasificaci칩n binaria podemos utilizar algo llamado matriz de confusi칩n. Una matriz de confusi칩n se ve as칤:

<div style="padding: 10px; margin: 20px"><img src='./Imgs/sesion_8-6.png'></div>

Es una matriz de 2x2 donde el eje x son los resultados estimados por el modelo entrenado y el eje y es la realidad (las etiquetas originales en nuestro dataset de prueba).

Analicemos a detalle esta matriz de confusi칩n.

> 

[**`Ejemplo 3`**](Ejemplo-03/matriz_de_confusion.ipynb)
[**`Reto 3`**](Reto-03/matriz_de_confusion.ipynb)

---

<ins>Curva ROC / AUC</ins>

La curva ROC / AUC es un m칠todo de evaluaci칩n de modelos de clasificaci칩n utilizando diferentes *umbrales*. Una gr치fica de curva ROC / AUC se ve as칤:

<div style="padding: 10px; margin: 20px"><img src='./Imgs/sesion_8-9.png'></div>

Veamos esta gr치fica con m치s detalle.

> 

[**`Ejemplo 4`**](Ejemplo-04/curva_roc_auc.ipynb)
[**`Reto 4`**](Reto-04/curva_roc_auc.ipynb)

---

## Postwork

[**`Postwork Sesi칩n 8`**](Postwork/Readme.md)
